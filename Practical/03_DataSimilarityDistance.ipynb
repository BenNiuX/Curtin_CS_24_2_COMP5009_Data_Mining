{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Dcw7Zoo7V6"
      },
      "source": [
        "# Practical 03 Data Similarity and Distance\n",
        "In this pract we will be exploring the concepts of data similarity and data distance.\n",
        "\n",
        "As usual we will be using Jupyter Notebooks, Google Collab, and Python/Pandas. The data for this week can be found on [GitHub](https://github.com/PaulHancock/COMP5009_pracs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AhHtkeCpNaU"
      },
      "source": [
        "# Q3 from Chapter 3 of [Aggarwal](https://www.springer.com/gp/book/9783319141411)\n",
        "\n",
        "We will be working with the [*Ionosphere*](http://archive.ics.uci.edu/ml/datasets/Ionosphere) data set from the UCI Machine Learning Repository.\n",
        "\n",
        "1. Copy the file `ionosphere.data` into the collaboratory space.\n",
        "  - Review the file `ionosphere.names` if you want some context for the data\n",
        "2. Compute the $L_p$ distances between all pairs of the first 10 data points, for p = 1, 2, and $\\infty$\n",
        "3. Compute the contrast measure on the data set for each norm.\n",
        "  - Repeat the exercise after samling the first $r$ dimensions, where $r$ varies from 1 to the full dimensionality of the data.\n",
        "  - Make a plot of contrast vs $r$, compare to figure 3.1 (a) of Aggarwal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxp7wZw0rrq7"
      },
      "source": [
        "## 1. Copy the file `ionosphere.data` into the collaboratory space.\n",
        "We want to be able to inspect the files before loading them so we'll download them into a local directory first.\n",
        "To do this we need to use the `urllib` module.\n",
        "\n",
        "Despite the name of the file (`ionosphere.data`) the format is `.csv` so save the file with the appropriate extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSlTf6YYsGUq"
      },
      "source": [
        "import urllib\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCaCNBdysdxz"
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/ionosphere.csv'\n",
        "file_name = 'ionosphere.csv'\n",
        "urllib.request.urlretrieve(data_url, file_name)\n",
        "# now do the same for the ionosphere.names file (at the same location)\n",
        "# data_url2 = \"\"\n",
        "# file_name2 = \"\"\n",
        "# urllib.request.urlretrieve(?, ?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvZw3KFf0_45"
      },
      "source": [
        "Once you have copied the files using the above code, navigate to them and have  a quick look at the raw data and the description file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zqxlsWrtYBT"
      },
      "source": [
        "## 2 Compute $L_p$ distances\n",
        "Compute the $L_p$ distances between all pairs of the first 10 data points, for p = 1, 2, and $\\infty$.\n",
        "\n",
        "Note: As per `ionosphere.names` the final attribute is a class attribute either 'g', or 'b'.\n",
        "We don't want to include non-numeric data when computing the $L_p$ norms, so we must drop this attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udZweCsBvTj3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtb7FMCuBuA"
      },
      "source": [
        "all_data = pd.read_csv('ionosphere.csv',\n",
        "                       header=None) # this csv file has no header\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the colum with label 34\n",
        "df = all_data.drop(colmuns=34)"
      ],
      "metadata": {
        "id": "WCgZRvkiClma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view just one row\n",
        "# we can't use df[0] since that will default to a column index not a row index\n",
        "# instead we use the integer locator `iloc` which we can index as if it were a numpy array\n",
        "# so df.iloc[0] is the first row\n",
        "# df.iloc[0:5,0] would be the first 5 rows, but just the first column\n",
        "df.iloc[0]"
      ],
      "metadata": {
        "id": "VqsHZeN5hbTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note that the above shows both the row values and the row indexes\n",
        "# if we want just the values we have to use `.values`\n",
        "df.iloc[0].values"
      ],
      "metadata": {
        "id": "hTTF4FCahymB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui8WqqOguSWt"
      },
      "source": [
        "# lets write separate functions for each of the lp norms\n",
        "def l1(first_row, second_row):\n",
        "  \"\"\"\n",
        "  Compute the $L_1$ distance between two rows of data\n",
        "  L1(x,y) = Σ_i | x_i-y_i |\n",
        "  \"\"\"\n",
        "  dist = ?\n",
        "  return dist\n",
        "\n",
        "def l2(first_row, second_row):\n",
        "  \"\"\"\n",
        "  Compute the $L_2$ distance between two rows of data\n",
        "  L2(x,y) = √(Σ_i | x_i-y_i |^2)\n",
        "  \"\"\"\n",
        "  dist = ?\n",
        "  return dist\n",
        "\n",
        "def linf(first_row, second_row):\n",
        "  \"\"\"\n",
        "  Compute the $L_\\infty$ distance between two rows of data\n",
        "  Linf(x,y) = max(|x-y|)\n",
        "  \"\"\"\n",
        "  dist = ?\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7x8HiKzvrFr"
      },
      "source": [
        "# # test that our function(s) work on the first two rows, using all three norms\n",
        "# We expect that Linf <= L2 <= L1\n",
        "print(f\"L1 = {l1(df.iloc[0], df.iloc[1])}\")\n",
        "print(f\"L2 = {l2(df.iloc[0], df.iloc[1])}\")\n",
        "print(f\"Linf = {linf(df.iloc[0], df.iloc[1])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyPDJl6Y10UU"
      },
      "source": [
        "We now have functions which will compute L for p=1,2,$\\infty$, so we must set up a list of all the combinations of the first 10 rows. `itertools` has a function exactly for this: `combinations`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9fvatnmvvfC"
      },
      "source": [
        "# Generate all pairs of rows from the first 10\n",
        "from itertools import combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbH0atUgw-Vq"
      },
      "source": [
        "# accessing the first 10 rows we use df.iloc[:10]\n",
        "# our functions want to work on lists of values so we chain the above with .values\n",
        "\n",
        "pairs = combinations(df.iloc[:10].values, # the items from which we are sampling\n",
        "                     2)                   # the number of samples to take at a time\n",
        "lp1_dist = []\n",
        "lp2_dist = []\n",
        "lpinf_dist = []\n",
        "for r1, r2 in pairs:\n",
        "  lp1_dist.append(l1(r1,r2))\n",
        "  lp2_dist.append(l2(r1,r2))\n",
        "  lpinf_dist.append(linf(r1,r2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyaEhsFAxDEF"
      },
      "source": [
        "# Summarise our data\n",
        "print(f\"Mean of $L_1$ over first 10 rows: {np.mean(lp1_dist):.2f}\")\n",
        "print(f\"Mean of $L_2$ over first 10 rows: {np.mean(lp2_dist):.2f}\")\n",
        "print(f\"Mean of $L_\\infty$ over first 10 rows: {np.mean(lpinf_dist):.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkHGgqX-2iKi"
      },
      "source": [
        "# check that we have always positive values\n",
        "lp1_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP7vOnSDzmE9"
      },
      "source": [
        "## 3 Compute the contrast measure\n",
        "Compute the contrast measure on the data set for each norm.\n",
        "  - Repeat the exercise after samling the first $r$ dimensions, where $r$ varies from 1 to the full dimensionality of the data.\n",
        "  - Make a plot of contrast vs $r$, compare to figure 3.1 (a) of Aggarwal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqmC6FXY0SgH"
      },
      "source": [
        "\n",
        "Recall that the contrast measure is given by\n",
        "\n",
        "$Contrast(D) = \\frac{D_{max} - D_{min}}{\\mu}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhPy1TKnx9OW"
      },
      "source": [
        "# It would be good to start by computing the distances for all data to some reference point, for each of the $L_p$ norms.\n",
        "r1 = df.iloc[0].values\n",
        "lp1_dist = []\n",
        "lp2_dist = []\n",
        "lpinf_dist = []\n",
        "for r2 in df.iloc[1:].values:\n",
        "  lp1_dist.append(l1(r1,r2))\n",
        "  lp2_dist.append(l2(r1,r2))\n",
        "  lpinf_dist.append(linf(r1,r2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArKzvAXZ0ikN"
      },
      "source": [
        "# Use the given definition to create a function which computes contrast from a set of distances\n",
        "def contrast(D):\n",
        "  \"\"\"\n",
        "  Compute the contrast of a data set with the given distances.\n",
        "  \"\"\"\n",
        "  c = ?\n",
        "  return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUqk1hEL00L_"
      },
      "source": [
        "# report the contrast for each lp norm\n",
        "print(f\"Contrast for p=1: {contrast(lp1_dist):.2f}\")\n",
        "print(f\"Contrast for p=2: {contrast(lp2_dist):.2f}\")\n",
        "print(f\"Contrast for p=inf: {contrast(lpinf_dist):.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2MTeegt01Zc"
      },
      "source": [
        "# As per the question we now compute this for various number of dimensions r\n",
        "c1 = []\n",
        "c2 = []\n",
        "cinf = []\n",
        "r_values = ? # a list of the number of dimensions that we want to iterate over\n",
        "\n",
        "# this is brute force and is not optimised for speed so will take a mintute or two to complete\n",
        "for r in r_values:\n",
        "  r1 = df.iloc[1,:r].values\n",
        "  lp1_dist = []\n",
        "  lp2_dist = []\n",
        "  lpinf_dist = []\n",
        "  for r2 in df.iloc[1:, :r].values:\n",
        "    lp1_dist.append(l1(r1,r2))\n",
        "    lp2_dist.append(l2(r1,r2))\n",
        "    lpinf_dist.append(linf(r1,r2))\n",
        "  c1.append(contrast(lp1_dist))\n",
        "  c2.append(contrast(lp2_dist))\n",
        "  cinf.append(contrast(lpinf_dist))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMz6I0RT59a4"
      },
      "source": [
        "# import matplotlib for plotting\n",
        "# make it so that the plots occur inline instead of in a pop-up window\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpktTj82EHR"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.plot(r_values, c1, label=\"$L_1$\")\n",
        "ax.plot(r_values, c2, label=\"$L_2$\")\n",
        "ax.plot(r_values, cinf, label=\"$L_\\infty$\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Data dimensions\")\n",
        "ax.set_ylabel(\"Contrast\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBp2Hue53c2F"
      },
      "source": [
        "Comparing this to the plot in the text book we can see the same behavior:\n",
        "- Hihger 'p' values means lower contrast\n",
        "- Higher dimenstions means lower contrast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwBGiiL38GGK"
      },
      "source": [
        "# Q6 from Chapter 3 of [Aggarwal](https://www.springer.com/gp/book/9783319141411)\n",
        "\n",
        "For this task we will use the KDD Cup 1999 data from last week.\n",
        "\n",
        "1. The data are available via github as [kddcup.arff](https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/kddcup99.arff), load them as a pandas data frame.\n",
        "2. Remove the numeric attributes and keep only categorical attributes.\n",
        "3. Remove all duplicate rows.\n",
        "4. Randomly pick a data point (row) and compute it's similarity to all other rows uing:\n",
        "  - Inverse Occurance Frequency Measure\n",
        "  - Overlap Measure\n",
        "5. Find the nearest neighbour for your randomly chosen data point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1AGx7bv9VEQ"
      },
      "source": [
        "## 1 Load the data\n",
        "We did this exactly last week so just copy across"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s40F68Aa2Hv4"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import urllib\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqzX-4I09kE_"
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/kddcup99.arff'\n",
        "file_name = 'kddcup99.arff'\n",
        "# this will download the file, look in your explorer to confirm\n",
        "urllib.request.urlretrieve(data_url, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YBDQEe79mV7"
      },
      "source": [
        "# load the data from arff format\n",
        "data = arff.loadarff(file_name)\n",
        "raw_df = pd.DataFrame(data[0]) # note the [0] here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ufx_gvU4kCb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1126d242-2742-41f8-ea76-3cede96f366f"
      },
      "source": [
        "raw_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           duration     src_bytes     dst_bytes  wrong_fragment   urgent  \\\n",
              "count  10000.000000  1.000000e+04   10000.00000     10000.00000  10000.0   \n",
              "mean      44.290800  1.560068e+03     667.65390         0.00560      0.0   \n",
              "std      688.058585  5.159270e+04   10134.22562         0.12558      0.0   \n",
              "min        0.000000  0.000000e+00       0.00000         0.00000      0.0   \n",
              "25%        0.000000  4.800000e+01       0.00000         0.00000      0.0   \n",
              "50%        0.000000  5.730000e+02       0.00000         0.00000      0.0   \n",
              "75%        0.000000  1.032000e+03       0.00000         0.00000      0.0   \n",
              "max    23815.000000  5.133876e+06  954639.00000         3.00000      0.0   \n",
              "\n",
              "                hot  num_failed_logins  lnum_compromised  lroot_shell  \\\n",
              "count  10000.000000        10000.00000      10000.000000   10000.0000   \n",
              "mean       0.044300            0.00030          0.006400       0.0001   \n",
              "std        0.842501            0.02236          0.080992       0.0100   \n",
              "min        0.000000            0.00000          0.000000       0.0000   \n",
              "25%        0.000000            0.00000          0.000000       0.0000   \n",
              "50%        0.000000            0.00000          0.000000       0.0000   \n",
              "75%        0.000000            0.00000          0.000000       0.0000   \n",
              "max       30.000000            2.00000          2.000000       1.0000   \n",
              "\n",
              "       lsu_attempted  ...  dst_host_count  dst_host_srv_count  \\\n",
              "count     10000.0000  ...    10000.000000        10000.000000   \n",
              "mean          0.0001  ...      232.449900          189.962600   \n",
              "std           0.0100  ...       64.617617          105.242412   \n",
              "min           0.0000  ...        1.000000            1.000000   \n",
              "25%           0.0000  ...      255.000000           68.750000   \n",
              "50%           0.0000  ...      255.000000          255.000000   \n",
              "75%           0.0000  ...      255.000000          255.000000   \n",
              "max           1.0000  ...      255.000000          255.000000   \n",
              "\n",
              "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
              "count            10000.000000            10000.000000   \n",
              "mean                 0.758506                0.028212   \n",
              "std                  0.407448                0.099844   \n",
              "min                  0.000000                0.000000   \n",
              "25%                  0.530000                0.000000   \n",
              "50%                  1.000000                0.000000   \n",
              "75%                  1.000000                0.030000   \n",
              "max                  1.000000                1.000000   \n",
              "\n",
              "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
              "count                 10000.000000                 10000.000000   \n",
              "mean                      0.600880                     0.006808   \n",
              "std                       0.481548                     0.043186   \n",
              "min                       0.000000                     0.000000   \n",
              "25%                       0.000000                     0.000000   \n",
              "50%                       1.000000                     0.000000   \n",
              "75%                       1.000000                     0.000000   \n",
              "max                       1.000000                     1.000000   \n",
              "\n",
              "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
              "count          10000.000000              10000.000000          10000.000000   \n",
              "mean               0.176059                  0.175725              0.055649   \n",
              "std                0.380065                  0.380314              0.225521   \n",
              "min                0.000000                  0.000000              0.000000   \n",
              "25%                0.000000                  0.000000              0.000000   \n",
              "50%                0.000000                  0.000000              0.000000   \n",
              "75%                0.000000                  0.000000              0.000000   \n",
              "max                1.000000                  1.000000              1.000000   \n",
              "\n",
              "       dst_host_srv_rerror_rate  \n",
              "count              10000.000000  \n",
              "mean                   0.054896  \n",
              "std                    0.224883  \n",
              "min                    0.000000  \n",
              "25%                    0.000000  \n",
              "50%                    0.000000  \n",
              "75%                    0.000000  \n",
              "max                    1.000000  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68e86c2d-963a-4442-b6ad-c9d40a690a9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>lnum_compromised</th>\n",
              "      <th>lroot_shell</th>\n",
              "      <th>lsu_attempted</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.0000</td>\n",
              "      <td>10000.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>44.290800</td>\n",
              "      <td>1.560068e+03</td>\n",
              "      <td>667.65390</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044300</td>\n",
              "      <td>0.00030</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>...</td>\n",
              "      <td>232.449900</td>\n",
              "      <td>189.962600</td>\n",
              "      <td>0.758506</td>\n",
              "      <td>0.028212</td>\n",
              "      <td>0.600880</td>\n",
              "      <td>0.006808</td>\n",
              "      <td>0.176059</td>\n",
              "      <td>0.175725</td>\n",
              "      <td>0.055649</td>\n",
              "      <td>0.054896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>688.058585</td>\n",
              "      <td>5.159270e+04</td>\n",
              "      <td>10134.22562</td>\n",
              "      <td>0.12558</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.842501</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.080992</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>...</td>\n",
              "      <td>64.617617</td>\n",
              "      <td>105.242412</td>\n",
              "      <td>0.407448</td>\n",
              "      <td>0.099844</td>\n",
              "      <td>0.481548</td>\n",
              "      <td>0.043186</td>\n",
              "      <td>0.380065</td>\n",
              "      <td>0.380314</td>\n",
              "      <td>0.225521</td>\n",
              "      <td>0.224883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>68.750000</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.730000e+02</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032000e+03</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>23815.000000</td>\n",
              "      <td>5.133876e+06</td>\n",
              "      <td>954639.00000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68e86c2d-963a-4442-b6ad-c9d40a690a9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68e86c2d-963a-4442-b6ad-c9d40a690a9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68e86c2d-963a-4442-b6ad-c9d40a690a9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mckCGoAH4mo9"
      },
      "source": [
        "## 2 Remove numeric attributes\n",
        "Remove the numeric attributes and keep only categorical attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3yEpe4W9n_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9545007-0e0c-4105-df7b-f37d905ce0b9"
      },
      "source": [
        "# Determine the data type for each coulmn\n",
        "raw_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "duration                       float64\n",
              "protocol_type                   object\n",
              "service                         object\n",
              "flag                            object\n",
              "src_bytes                      float64\n",
              "dst_bytes                      float64\n",
              "land                            object\n",
              "wrong_fragment                 float64\n",
              "urgent                         float64\n",
              "hot                            float64\n",
              "num_failed_logins              float64\n",
              "logged_in                       object\n",
              "lnum_compromised               float64\n",
              "lroot_shell                    float64\n",
              "lsu_attempted                  float64\n",
              "lnum_root                      float64\n",
              "lnum_file_creations            float64\n",
              "lnum_shells                    float64\n",
              "lnum_access_files              float64\n",
              "lnum_outbound_cmds             float64\n",
              "is_host_login                   object\n",
              "is_guest_login                  object\n",
              "count                          float64\n",
              "srv_count                      float64\n",
              "serror_rate                    float64\n",
              "srv_serror_rate                float64\n",
              "rerror_rate                    float64\n",
              "srv_rerror_rate                float64\n",
              "same_srv_rate                  float64\n",
              "diff_srv_rate                  float64\n",
              "srv_diff_host_rate             float64\n",
              "dst_host_count                 float64\n",
              "dst_host_srv_count             float64\n",
              "dst_host_same_srv_rate         float64\n",
              "dst_host_diff_srv_rate         float64\n",
              "dst_host_same_src_port_rate    float64\n",
              "dst_host_srv_diff_host_rate    float64\n",
              "dst_host_serror_rate           float64\n",
              "dst_host_srv_serror_rate       float64\n",
              "dst_host_rerror_rate           float64\n",
              "dst_host_srv_rerror_rate       float64\n",
              "label                           object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5HHNzZl9rsK"
      },
      "source": [
        "# note that the string columns are of type object so select just those\n",
        "df = raw_df.select_dtypes(include=object)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8wUYf8P_jvH"
      },
      "source": [
        "## 3 Remove duplicates\n",
        "Remove all duplicate rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOW74ns1-iUc"
      },
      "source": [
        "# no need for anything fancy, just use the drop_duplicates function\n",
        "cleaned_df = ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFAZigNb-uus",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a2673f48-22a8-4135-88a2-4572509cf73a"
      },
      "source": [
        "# see how many rows remain\n",
        "cleaned_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     protocol_type         service     flag  land logged_in is_host_login  \\\n",
              "0          b'icmp'        b'ecr_i'    b'SF'  b'0'      b'0'          b'0'   \n",
              "5           b'tcp'         b'smtp'    b'SF'  b'0'      b'1'          b'0'   \n",
              "6           b'udp'     b'domain_u'    b'SF'  b'0'      b'0'          b'0'   \n",
              "9           b'tcp'      b'private'    b'S0'  b'0'      b'0'          b'0'   \n",
              "19          b'tcp'     b'ftp_data'    b'SF'  b'0'      b'1'          b'0'   \n",
              "...            ...             ...      ...   ...       ...           ...   \n",
              "9507        b'tcp'  b'netbios_dgm'    b'S0'  b'0'      b'0'          b'0'   \n",
              "9521        b'tcp'      b'daytime'    b'S0'  b'0'      b'0'          b'0'   \n",
              "9586        b'tcp'      b'sql_net'   b'REJ'  b'0'      b'0'          b'0'   \n",
              "9592        b'tcp'       b'telnet'  b'RSTO'  b'0'      b'0'          b'0'   \n",
              "9993        b'tcp'     b'ftp_data'    b'SF'  b'0'      b'1'          b'0'   \n",
              "\n",
              "     is_guest_login         label  \n",
              "0              b'0'      b'smurf'  \n",
              "5              b'0'     b'normal'  \n",
              "6              b'0'     b'normal'  \n",
              "9              b'0'    b'neptune'  \n",
              "19             b'0'     b'normal'  \n",
              "...             ...           ...  \n",
              "9507           b'0'    b'neptune'  \n",
              "9521           b'0'    b'neptune'  \n",
              "9586           b'0'    b'neptune'  \n",
              "9592           b'0'     b'normal'  \n",
              "9993           b'0'  b'ftp_write'  \n",
              "\n",
              "[119 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4e524ae-2374-4178-89a2-991cd82eb268\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>land</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'icmp'</td>\n",
              "      <td>b'ecr_i'</td>\n",
              "      <td>b'SF'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'smurf'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'smtp'</td>\n",
              "      <td>b'SF'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'1'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'normal'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>b'udp'</td>\n",
              "      <td>b'domain_u'</td>\n",
              "      <td>b'SF'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'normal'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'private'</td>\n",
              "      <td>b'S0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'neptune'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'ftp_data'</td>\n",
              "      <td>b'SF'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'1'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'normal'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9507</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'netbios_dgm'</td>\n",
              "      <td>b'S0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'neptune'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9521</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'daytime'</td>\n",
              "      <td>b'S0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'neptune'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9586</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'sql_net'</td>\n",
              "      <td>b'REJ'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'neptune'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'telnet'</td>\n",
              "      <td>b'RSTO'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'normal'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>b'tcp'</td>\n",
              "      <td>b'ftp_data'</td>\n",
              "      <td>b'SF'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'1'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'ftp_write'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>119 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e524ae-2374-4178-89a2-991cd82eb268')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4e524ae-2374-4178-89a2-991cd82eb268 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4e524ae-2374-4178-89a2-991cd82eb268');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notice that we have 119 rows, but the row indexes haven't been updated\n",
        "# we can update them to avoid some confusion later\n",
        "cleaned_df.reset_index(inplace=True)\n",
        "cleaned_df"
      ],
      "metadata": {
        "id": "JKlfpjoDin84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOtYmb7_qMW"
      },
      "source": [
        "## 4 Randomly pick a data point and compute ...\n",
        "Randomly pick a data point (row) and compute it's similarity to all other rows uing:\n",
        "  - Inverse Occurance Frequency Measure\n",
        "  - Match Measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU3Rv6Rd8bok"
      },
      "source": [
        "Firstly we must choose a row at random."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdSI1hGF_pKw"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxX2JZXZ_0EO"
      },
      "source": [
        "my_row_number = random.randint(0, # minimum value to choose\n",
        "                               ?) # maximum value, should be the number of rows in our data frame\n",
        "my_row = cleaned_df.iloc[my_row_number]\n",
        "\n",
        "print(f\"I chose instance {my_row_number}:\")\n",
        "print( \"----------------------------\")\n",
        "print(my_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs6ZPb7i8f9e"
      },
      "source": [
        "### Inverse Occurance Frequency Meausre (IOFM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qf-OiYWCgAB"
      },
      "source": [
        "For inverse occurance frequency measure we need to determine what the frequencies are for each value of each attribute.\n",
        "The python builtin `set` type is useful here as it defines an unordered list of **unique** items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc639hJsAD9B"
      },
      "source": [
        "# use set to reduce all our values to a set of unique values\n",
        "for attribute in cleaned_df.columns:\n",
        "  print(f\"Attribute {attribute} has values {set(cleaned_df[attribute])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "851Z3G3ICzfl"
      },
      "source": [
        "# lets create a function which will create a lookup table of the pk values\n",
        "def attribute_frequencies(dataframe):\n",
        "  \"\"\"\n",
        "  Construct a dictionary px, such that the probability of attribute a, having value x, for the given data set is:\n",
        "  pk[a][x]\n",
        "  \"\"\"\n",
        "  pk = {} # pk will be a dictionary which we can index using the attribute name\n",
        "  for attribute in dataframe.columns:\n",
        "    column = dataframe[attribute]\n",
        "    categories = set(column)\n",
        "    frequencies = {}\n",
        "    for c in categories:\n",
        "      frequencies[c] = np.sum(column == c)/column.shape[0]\n",
        "    pk[attribute] = frequencies\n",
        "  return pk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrbZzjURFfzM"
      },
      "source": [
        "# test that the function works, hand looks to give sensible results\n",
        "pk = attribute_frequencies(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpntEILvGmTr"
      },
      "source": [
        "Now we should create another functions with computes S defined as:\n",
        "\n",
        "$ S(x,y) = 1/p_k(x_i)^2 $ if $x_i = y_i$ and zero otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0uk_dBFFmEq"
      },
      "source": [
        "def iofm(first_row, second_row):\n",
        "  \"\"\"\n",
        "  Compute the inverse occurance frequency measure (iofm) for two rows.\n",
        "  \"\"\"\n",
        "  sim = 0\n",
        "  # a pandas series (row) doesn't have columns or column names, but keys\n",
        "  for attribute in first_row.keys():\n",
        "    # we access the rows using these keys the same way we would columns of a dataframe\n",
        "    if first_row[attribute] == second_row[attribute]:\n",
        "      sim += 1/pk[attribute][first_row[attribute]]**2\n",
        "  return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above we have a dictionary `pk` which contains another set of dictionaries.\n",
        "This is how we construct our look up table.\n",
        "Therefore we have a double indexing:\n",
        "- `pk[attribute]` will select the lookup table for the given attribute. This is a map of `category -> frequency`\n",
        "- `pk[attribute][category]` will then select the given category and return the frequency.\n",
        "Finally, `first_row[attribute]` will extract the `category` corresponding to `attribute` from the first row."
      ],
      "metadata": {
        "id": "r1vtg-ErjBUj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JucYk-jMHpMj"
      },
      "source": [
        "# test that our similarity measure works\n",
        "# each row should be very similar to itself!\n",
        "iofm(my_row, my_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpgNN9iSHy_N"
      },
      "source": [
        "best_row = None\n",
        "best_similar = 0\n",
        "# iterating over rows we have to use the .iterrows() function\n",
        "# which returns both the row index, as well as the row\n",
        "for index, row in cleaned_df.iterrows():\n",
        "  if index != my_row_number: # don't allow my_row to be the best match!\n",
        "    similar = ? # compute the similarity between this row and my_row\n",
        "    if similar > best_similar:\n",
        "      best_row = ? # update the best_row to be the current row\n",
        "      best_similar = ? # update the best_similar to be the just calculated similarity\n",
        "\n",
        "print(f\"Using Inverse Occurance Frequency Measure the nearest neighbour for my row is:\\n{best_row}\\nwith similarity score of {similar}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OfaS1f28Qk-"
      },
      "source": [
        "### Overlap Measure\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NSkg8ou9qk2"
      },
      "source": [
        "This is the same as the IOFM but simplified to\n",
        "\n",
        "$ S(x,y) = 1$ if $x_i = y_i$ and zero otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnSs8ukm8nVL"
      },
      "source": [
        "def overlap(first_row, second_row):\n",
        "  \"\"\"\n",
        "  Compute the overlap measure for two rows.\n",
        "  \"\"\"\n",
        "  sim = 0\n",
        "  # a pandas series (row) doesn't have columns or column names, but keys\n",
        "  for attribute in first_row.keys():\n",
        "    # we access the rows using these keys the same way we would columns of a dataframe\n",
        "    if first_row[attribute] == second_row[attribute]:\n",
        "      sim += 1\n",
        "  return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU_RddaH90Pj"
      },
      "source": [
        "# test that our similarity measure works\n",
        "# each row should be very similar to itself!\n",
        "overlap(my_row, my_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51NDbms926D"
      },
      "source": [
        "best_row = None\n",
        "best_similar = 0\n",
        "# iterating over rows we have to use the .iterrows() function\n",
        "# which returns both the row index, as well as the row\n",
        "for index, row in cleaned_df.iterrows():\n",
        "  if index != my_row_number: # don't allow my_row to be the best match!\n",
        "    similar = ?\n",
        "    if similar > best_similar:\n",
        "      ?\n",
        "print(f\"Using Overlap Measure the nearest neighbour for my row is:\\n{best_row}\\nwith similarity score of {similar}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb5tTK9M-JvK"
      },
      "source": [
        "## 5 Find the nearest neighbour\n",
        "\n",
        "Do your two nearest neighbour calculations agree?\n",
        "\n",
        "Do you exepect that your nerest neighbour is unique or just one among many?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgSFnGGW-cPa"
      },
      "source": [
        "Depending on your chosen random datapoint you may have different answers for part 1, however for part 2 our algorithm didn't record multiple matches for the largest similarity so we don't know if it's unique. For the overlap measure, given that the possible similarity scores are 1 to 8, I would think that there is some likelyhood that there may be multiple neighbours at a similarity of 4 that are equally good matches."
      ]
    }
  ]
}