{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUQE3Da1tUd7"
      },
      "source": [
        "# Supermarket basket association pattern mining\n",
        "\n",
        "In this question, we perform association pattern mining using the supermarket dataset `supermarket.arff` from the [Weka MOOC](https://www.cs.waikato.ac.nz/ml/weka/courses.html).\n",
        "\n",
        "\n",
        "1. Load the data file `supermarket.arff` into a pandas data frame\n",
        "\n",
        "2. Remove the following attributes\n",
        "  - `department*`\n",
        "  - `non host support`\n",
        "  - `total`\n",
        "\n",
        "3.  Select the Apriori algorithm and perform frequent itemset mining with minsup = 0.2 and minconf = 0.8 and find out:\n",
        "  - The numbers of frequent 2-itemsets, and 3-itemsets.\n",
        "  - The best three (2) rules with largest confidence. Examine these rules and describe them in your own words.\n",
        "\n",
        "4. The supermarket manager wishes to boost the sale of fruit and therefore the manager needs to know other itemsets most likely be purchased with fruit to make promotion decisions.\n",
        "  - Using the same minimum support and minimum confidence value.\n",
        "  - List the top three itemsets to report to the supermarket manager.\n",
        "\n",
        "5. Repeat task 3, but using the FP Growth algorithm instead.  \n",
        "  - Compare the rules found.\n",
        "  - Are they consistent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sesbe9KEL5tx"
      },
      "source": [
        "## 0 Upgrade mlxtend\n",
        "The default version of `mlxtend` on Google Colaborate is too old for this prac\n",
        "so we must upgrade it. We want something that is at least version 0.18.\n",
        "Note that code statements beginning with `!` are not python code, but system calls. If you are running this in a personal jupyterlab you might have to update this module a different way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFBB2RsZf79_"
      },
      "source": [
        "! pip install --upgrade 'mlxtend>=0.18'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYe47OJWf8h0"
      },
      "source": [
        "# Check we have the right version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you ran the two cells above inreverse order then you'll have to restart the kernel before you can load the newer version of the `mlxtend` module.\n",
        "\n",
        "To do this: choose \"Runitime\" -> \"Restart runtime\"."
      ],
      "metadata": {
        "id": "C4cxgU6hBBvt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4nbxT6vtBd9"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import urllib\n",
        "import urllib.request\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-jloVtsMriH"
      },
      "source": [
        "## 1 Load the data file `supermarket.arff` into a pandas data frame\n",
        "\n",
        "We did this in a previous prac: download the file into your working directory using `urrlib`, load it using `scipy`, and then convert to a `pandas` data frame. The file on the Weka website has a few problems that we need to work around, so I've provided a cleaned version of the data on [GitHub](https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/supermarket.arff)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHP3pP7ms034"
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/supermarket.arff'\n",
        "file_name = 'supermarket.arff'\n",
        "urllib.request.urlretrieve(data_url, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkG2OE8ptOtk"
      },
      "source": [
        "# load the data from arff format\n",
        "data = arff.loadarff('supermarket.arff')\n",
        "raw_df = pd.DataFrame(data[0])\n",
        "# The data table is 1 and 0, but we want it to be boolean (true/false) so we\n",
        "# need to convert from int -> bool\n",
        "df = raw_df.astype(?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wbo3P65tRfR"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-i7Z3PwQkiB"
      },
      "source": [
        "## 2 Remove attributes\n",
        "Remove the following attributes as they have been deemed to be not-useful:\n",
        "  - `department*`\n",
        "  - `non host support`\n",
        "  - `total`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz4kpMryQwcv"
      },
      "source": [
        "cols_to_drop = ['non host support', 'total']\n",
        "# Instead of hand writing all the names that start with department, use a loop\n",
        "for col in df.columns:\n",
        "  if col.startswith(?): # choose all the columns which start with the word 'department'\n",
        "    cols_to_drop.append(col)\n",
        "print(\"The folloiwing columns will be dropped:\")\n",
        "print(cols_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDaU8qX_RSVN"
      },
      "source": [
        "df = df.drop(columns=cols_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2cp1xD1RaPr"
      },
      "source": [
        "# confirm we have dropped the columns by showing a summary, we should have 104 cols left, all with descriptive names.\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND5nK5G2Rq1i"
      },
      "source": [
        "## 3 Select the Apriori algorithm\n",
        "\n",
        "Select the Apriori algorithm and perform frequent itemset mining with `minsup = 0.2` and `minconf = 0.8` and find out:\n",
        "\n",
        "- The numbers of frequent 2-itemsets, and 3-itemsets.\n",
        "- The best three rules with largest confidence. Examine these rules and describe them in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_wQ33C0R4G_"
      },
      "source": [
        "The `apriori` algorithm is found in the `mlxtend` package, so we import it along with the `association_rules` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2QfjzYtrca"
      },
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH8DMnP0ve2r"
      },
      "source": [
        "ap_itemsets = apriori(df,\n",
        "                      min_support=?,  # choose the (relative) minsup\n",
        "                      use_colnames=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap_itemsets"
      ],
      "metadata": {
        "id": "Z92t5vyLuSA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXljuPEcWMrY"
      },
      "source": [
        "Now that we have our itemsets we want to chose those with `2<=k<=3`.\n",
        "This isn't explicitly stored within our dataframe so we'll make a new column which is just the value of `len(itemsets)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g6y3hvZYqIj"
      },
      "source": [
        "def find_k(row):\n",
        "  \"\"\"Return the number of items in the itemset\"\"\"\n",
        "  return len(row['itemsets'])\n",
        "\n",
        "# Create a new column which counts the number of items in the itemset\n",
        "ap_itemsets['k'] = ap_itemsets.apply(?, # Apply the function `find_k`\n",
        "                                     axis=1) # apply the function to each row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap_itemsets"
      ],
      "metadata": {
        "id": "vKyK3r2zuUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Ksn907Wa7L"
      },
      "source": [
        "k2_itemsets = np.sum(ap_itemsets['k'] == ?) # count the number of rows where k=2\n",
        "k3_itemsets = np.sum(ap_itemsets['k'] == ?) # count the number of rows where k=3\n",
        "print(f\"There are {k2_itemsets} itemsets with k=2\")\n",
        "print(f\"There are {k3_itemsets} itemsets with k=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijC8V8UfLFZ6"
      },
      "source": [
        "# Now lets see the top 10 itemsets\n",
        "# try either .head() or .nlargest(10,'support')\n",
        "ap_itemsets.?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMcj28c4LQkz"
      },
      "source": [
        "Note that the top 10 itemsets are all 1-itemsets. Is this surprising to you?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndL2KS9eSsUM"
      },
      "source": [
        "We use these itemsets to generate association rules with a minimum confidence of 0.8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2jSPGsvoms"
      },
      "source": [
        "ap_rules = association_rules(ap_itemsets,\n",
        "                             metric='confidence',\n",
        "                             min_threshold=?) # choose the minimum confidence value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wmmvgHB4ywa"
      },
      "source": [
        "ap_rules.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xFyGBlTL1u"
      },
      "source": [
        "Note that the rules above are not sorted by confidence. We should do that ourselves by using the `sort_values` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KflkW0vSS_J3"
      },
      "source": [
        "ap_rules.sort_values('confidence', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_yT94ofTaA8"
      },
      "source": [
        "Now describe the first three that you see above in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHyYiku2TpdG"
      },
      "source": [
        "## 4 Boost fruit sales\n",
        "The supermarket manager wishes to boost the sale of fruit and therefore the manager needs to know other itemsets most likely be purchased with fruit to make promotion decisions.\n",
        "  - Using the same minimum support and minimum confidence value.\n",
        "  - List the top three itemsets to report to the supermarket manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXHZ-iF-MBqQ"
      },
      "source": [
        "# choose all the rules wihch have \"fruit\" (not canned fruit) as the consquent\n",
        "fruit_rules = ap_rules[ap_rules.consequents == frozenset([?])]\n",
        "\n",
        "fruit_rules.sort_values(?,  # sort based on 'confidence'\n",
        "                        ascending=False).head(3) # choose the top 3 only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqG1xep9OuZ7"
      },
      "source": [
        "## 5 FP-Growth\n",
        "Repeat task 3, but using the FP Growth algorithm instead.  \n",
        "  - Compare the rules found.\n",
        "  - Are they consistent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlhJDkJlPA5l"
      },
      "source": [
        "Import the `fpgrowth` function from our `mlxtend` module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksp_hczq0EgW"
      },
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RrIK42Ve_Xv"
      },
      "source": [
        "fp_itemsets = fpgrowth(df,\n",
        "                       min_support=?, # choose the minimum support\n",
        "                       use_colnames=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942LR6AhgYOt"
      },
      "source": [
        "fp_rules = association_rules(fp_itemsets,\n",
        "                             metric='confidence',\n",
        "                             min_threshold=?) # choose the minimum confidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDcUV0QhPMdA"
      },
      "source": [
        "There are a lot of rules, lets compare just the first 10 most confident rules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSeodYelhckj"
      },
      "source": [
        "# Select the top 10 confident rules from each of our algorithms\n",
        "fp_top_10 = fp_rules.sort_values('confidence', ascending=False).head(10)\n",
        "ap_top_10 = ap_rules.sort_values('confidence', ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McBW4hh_hfMB"
      },
      "source": [
        "print(\"FP-Growth rules\")\n",
        "fp_top_10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPqi8T6RqjT"
      },
      "source": [
        "print(\"Apriori rules\")\n",
        "ap_top_10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xycAJ2gKR0GJ"
      },
      "source": [
        "Do the above tables agree?"
      ]
    }
  ]
}