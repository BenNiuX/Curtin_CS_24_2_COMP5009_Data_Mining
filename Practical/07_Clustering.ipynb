{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp5tcVGUQVmQ"
      },
      "source": [
        "# Prac 06 Clustering\n",
        "\n",
        "In this prac we will explore some of the clustering methods available in `sklearn` as well as some of the metrics that we can use to evalutate them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2oOZ3yOcRKA"
      },
      "source": [
        "# Q1\n",
        "As a warm-up we will start by simulating some data with known labels, and then test out our clustering algorithms using the sum of squared errors.\n",
        "\n",
        "1. Generate a simulated data set with three classes and three dimensions.\n",
        "  - Visualise the data.\n",
        "1. Using the bottom up aglomerative clustering method\n",
        "  - cluster the data set and determine the optimal number of clusters\n",
        "  - recluster the data using this optimal clustering\n",
        "  - view the data clusters\n",
        "1. Compute the sum of squared errors for each cluster.\n",
        "  - Write a function to compute sume of squared errors.\n",
        "1. For each clustering method that was discussed in class (DBSCAN, KMeans, and Gaussian Mixture):\n",
        "  - Cluster the data\n",
        "  - Evaluate the SSQ\n",
        "  - Identify the best clustering metric from the 4 methods tested so far\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwGtQsGhQXb3"
      },
      "source": [
        "Do the standard imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy5gG92ZTGHe"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtGlJui-Swjm"
      },
      "source": [
        "### 1 Generate data\n",
        "Use `sklearn.datasets.make_classification` to generate a data set with 1000 samples, 3 features, and 3 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvDh8PLXUoly"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000,\n",
        "                           n_features=3,\n",
        "                           n_informative=3,\n",
        "                           n_redundant=0,\n",
        "                           n_clusters_per_class=1,\n",
        "                           n_classes=3,\n",
        "                           class_sep=3,\n",
        "                           # flip_y=0, Leaving this as the defaul 0.001 gives a few 'errors' in the class labels\n",
        "                           random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0xMnjhxXNgk"
      },
      "source": [
        "Visualize the data using a 3D plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVzvXkghUxBh"
      },
      "source": [
        "def plot3d(X,y):\n",
        "  fig, ax = plt.subplots(1,1, subplot_kw={'projection':'3d'})\n",
        "\n",
        "  # create scatter plot for samples from each class\n",
        "  for class_value in pd.unique(y):\n",
        "    # get row indexes for samples with this class\n",
        "    row_ix = np.where(y == class_value)\n",
        "    # create scatter of these samples\n",
        "    ax.scatter(X[row_ix, 0], X[row_ix, 1], X[row_ix,2])\n",
        "  # show the plot\n",
        "  ax.set_xlabel('x')\n",
        "  ax.set_ylabel('y')\n",
        "  ax.set_zlabel('z')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41T1KTqPYNeg"
      },
      "source": [
        "plot3d(X,y)\n",
        "# Note that there are a few data points that seem to be sitting in the wrong cluster."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(X, columns=['x','y','z'])\n",
        "df2 = pd.DataFrame(y, columns=['cluster'])\n",
        "df = df1.join(df2)\n",
        "sns.pairplot(df, hue='cluster', palette=sns.color_palette('colorblind',3))"
      ],
      "metadata": {
        "id": "mtzrXp-mgfDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frvkncWCVp6M"
      },
      "source": [
        "### 2 Use the bottom up aglomerative clustering method\n",
        "Using the bottom up aglomerative clustering method, cluster the data set and determine the optimal number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NqelsxyaGCM"
      },
      "source": [
        "# import the method\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BEHC8QkV1DR"
      },
      "source": [
        "Firstly we run the clustering method with a distance threshold of zero and no indication of the number of clusters.\n",
        "This will generate *all* possible clusters, which we can then visualise and determine the optimal number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v98arimdDqQ"
      },
      "source": [
        "model_ac_full = AgglomerativeClustering(distance_threshold=0, n_clusters=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loXSOhezcyzA"
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
        "                                      counts]).astype(float)\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqs9AQAlWZEd"
      },
      "source": [
        "# Now plot the dendrogram.\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "# Fit the model\n",
        "model_ac_full.fit(X)\n",
        "# plot the top five levels of the dendrogram\n",
        "plot_dendrogram(model_ac_full, truncate_mode='level', p=5)\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o3jXidnWj-z"
      },
      "source": [
        "Using the method described in class, inspect the above figure, and decide how many clusters should be used.\n",
        "\n",
        "Once this has been done, redo the clustering with that number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wawNmAsdWtHl"
      },
      "source": [
        "model_ac = AgglomerativeClustering(n_clusters=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtt7ONBLYA-u"
      },
      "source": [
        "yhat =?\n",
        "plot3d(X,yhat)\n",
        "# note that the spurious data points shown before are not 'correctly' labeled."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(X, columns=['x','y','z'])\n",
        "df2 = pd.DataFrame(yhat, columns=['cluster'])\n",
        "df = df1.join(df2)\n",
        "sns.pairplot(df, hue='cluster', palette=sns.color_palette('colorblind',3))"
      ],
      "metadata": {
        "id": "SPtq9K3zVUFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JPN6UlFZIdi"
      },
      "source": [
        "### 3 Compute the sum of squared errors\n",
        "1. Compute the sum of squared errors (SSQ) for each cluster.\n",
        "  - Write a function to compute sume of squared errors.\n",
        "  - Print the SSQ for each cluster, and for the total."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gilKc0aqL4Qc"
      },
      "source": [
        "def calc_ssq(X, yhat):\n",
        "  clusters = np.unique(yhat)\n",
        "  ssq = 0\n",
        "  for c in clusters:\n",
        "    cluster = X[np.where(yhat==c)]\n",
        "    centroid = np.mean(cluster, axis=0)\n",
        "    distances = cluster-centroid\n",
        "    ssq += np.sum(distances**2)\n",
        "    #print(?)\n",
        "  #print(?)\n",
        "  return ssq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hZBaQTcZH6T"
      },
      "source": [
        "yhat = model_ac.fit_predict(X)\n",
        "calc_ssq(X, yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6s_H15DZ7rJ"
      },
      "source": [
        "### 4 Test further methods\n",
        "For each clustering method that was discussed in class (DBSCAN, KMeans, and Gaussian Mixture):\n",
        "  - Cluster the data assuming 3 clusters\n",
        "  - Evaluate the SSQ for that method\n",
        "  - Identify the best clustering metric from the 4 methods tested so far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjTP8KLfbASs"
      },
      "source": [
        "from sklearn.cluster import DBSCAN, KMeans\n",
        "from sklearn.mixture import GaussianMixture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGfRDEhbcXAO"
      },
      "source": [
        "model_gm = ?\n",
        "yhat = ?\n",
        "calc_ssq(X,yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACGpA61bvzd"
      },
      "source": [
        "model_km = ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt6o1a3LbC9P"
      },
      "source": [
        "model_db = ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiXnjVfqbodE"
      },
      "source": [
        "Note that DBSCAN doesn't allow you to specify a number of clusters.\n",
        "How many clusters were generated by DBSCAN and how many outlier points were there?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esT23jq-bwwf"
      },
      "source": [
        "# Look at the uniquie labels\n",
        "# -1 => noise/outlier\n",
        "# 0 or greater  => cluster label\n",
        "np.unique(model_db.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPjK0UFTcd-y"
      },
      "source": [
        "# Q2\n",
        "Using the datasets and classifiers from Q1 we will now explore different validation metrics, and how we can use them to choose the 'best' clustering properties.\n",
        "\n",
        "1. Use metrics discussed in class to evaluate each of the clustering methods in Q1\n",
        "  - Use metrics:\n",
        "    - sum of squared errors (SSQ)\n",
        "    - Silhouette\n",
        "    - Intra/Inter cluster distance ration, a.k.a the Davies Bouldin Score\n",
        "  - Use methods:\n",
        "    - Aglomerative\n",
        "    - GaussianMixture\n",
        "    - KMeans\n",
        "    - DBSCAN\n",
        "  - Create a matrix of metric/method showing the scores for each combination\n",
        "2. Using the KMeans clustering method:\n",
        "  - Measure the SSQ score for values of k=2-20\n",
        "  - Plot the result and choose the optimal value of k\n",
        "  - Repeat the above for the remaining metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDbivQZVgW3K"
      },
      "source": [
        "## 1 Create a matrix of scores\n",
        "Use metrics discussed in class to evaluate each of the clustering methods in Q1\n",
        "  - Use metrics:\n",
        "    - sum of squared errors (SSQ)\n",
        "    - Silhouette\n",
        "    - Intra/Inter cluster distance ration, a.k.a the Davies Bouldin Score\n",
        "  - Use methods:\n",
        "    - Aglomerative\n",
        "    - GaussianMixture\n",
        "    - KMeans\n",
        "    - DBSCAN\n",
        "  - Create a matrix of metric/method showing the scores for each combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFoCqBjPdSUU"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "methods = [model_ac, model_gm, model_km, model_db]\n",
        "scorers = [calc_ssq, metrics.davies_bouldin_score, metrics.silhouette_score]\n",
        "# see below for ordering of methods/scorers\n",
        "\n",
        "scores = np.empty(shape=(3,4))\n",
        "for i,m in enumerate(methods):\n",
        "  yhat = m.fit_predict(X)\n",
        "  for j,scorer in enumerate(scorers):\n",
        "    score = scorer(X,yhat)\n",
        "    scores[j,i] = score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY3CekdDek7e"
      },
      "source": [
        "df = pd.DataFrame(scores,\n",
        "                  columns=['Aglomerative', 'GaussianMixture', 'KMeans','DBSCAN'],\n",
        "                  index=[\"SSQ\", 'DaviesBouldin', 'Silhouette'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F88BKvMwf-WL"
      },
      "source": [
        "## 2 Use KMeans\n",
        "Using the KMeans clustering method:\n",
        "  - Measure the SSQ score for values of k=1-20\n",
        "  - Plot the result and choose the optimal value of k\n",
        "  - Repeat the above for the remaining metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gzf3VtlwQsW"
      },
      "source": [
        "km_ssq = []\n",
        "for k in range(?):\n",
        "  km = KMeans(n_clusters=k)\n",
        "  yhat = ?\n",
        "  ssq = calc_ssq(X,yhat)\n",
        "  #print(f\"k={k} ssq={ssq:.2f}\")\n",
        "  km_ssq.append(ssq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QExqz0klvnCV"
      },
      "source": [
        "k_vals = range(1,len(km_ssq)+1)\n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.plot(?,\n",
        "        ?,\n",
        "        'o-')\n",
        "ax.set_xlabel('k')\n",
        "ax.set_ylabel('SSQ')\n",
        "ax.set_xticks(k_vals)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXLK5aYszgQc"
      },
      "source": [
        "# now for the other two metrics"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}