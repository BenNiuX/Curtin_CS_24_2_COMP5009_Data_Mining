{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implement"
      ],
      "metadata": {
        "id": "Q7fRHnz_JHrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data preparation"
      ],
      "metadata": {
        "id": "-S74hCFCR6RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download sqlite DB from web."
      ],
      "metadata": {
        "id": "vk-PCdHa93Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -nc https://github.com/PaulHancock/COMP5009_pracs/raw/main/data/Assignment2024.sqlite"
      ],
      "metadata": {
        "id": "oPa0HbGvS3Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import related packages."
      ],
      "metadata": {
        "id": "EUlOUuXV97qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "q2dXfcl3S1WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con = sqlite3.connect('Assignment2024.sqlite')\n",
        "train_df = pd.read_sql(\"SELECT * FROM train\", con)\n",
        "test_df = pd.read_sql(\"SELECT * FROM test\", con)\n",
        "con.close()"
      ],
      "metadata": {
        "id": "IboLikxYTBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "iPPQLxkCU--4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "vbwjskQkje0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df = test_df['index'].copy().to_frame()"
      ],
      "metadata": {
        "id": "CcP23xqCoar1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df"
      ],
      "metadata": {
        "id": "Pl52b8rwpq6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names\")\n",
        "print(train_df.columns)\n",
        "print()\n",
        "print(\"Data types\")\n",
        "print(train_df.dtypes)\n",
        "print(train_df.shape)"
      ],
      "metadata": {
        "id": "KdIeVzE9VQya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(train_df['Music'][i], train_df['Storage'][i], train_df['Guitar'][i])"
      ],
      "metadata": {
        "id": "404Ktug4WAzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "9yGiqBC5T4HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.sum(numeric_only=True)"
      ],
      "metadata": {
        "id": "PbW9bw9yYfjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can plot a histogram of all the data together\n",
        "train_df_bak = train_df.copy()\n",
        "train_df_bak.hist(figsize=(12,12))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5bli15imYnIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_bak_desc = train_df_bak.describe()\n",
        "print(train_df_bak_desc.loc['std'])\n",
        "train_df_bak_desc.loc['std'].plot.line()\n",
        "plt.title('Standard Deviation of Each Attribute')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yw7OZ3yVYmhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_std_threshold = 100\n",
        "outlier_columns = []\n",
        "\n",
        "for column in train_df_bak.columns:\n",
        "  if 'object' != train_df_bak.dtypes[column] and train_df_bak_desc[column]['std'] > config_std_threshold:\n",
        "    print(column, train_df_bak_desc[column]['std'])\n",
        "    if column != 'index':\n",
        "      outlier_columns.append(column)\n",
        "print(outlier_columns)"
      ],
      "metadata": {
        "id": "bTAuCziORuz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler(copy=False)\n",
        "# Determine the mean/std for each column and set up the scaler\n",
        "print(outlier_columns)\n",
        "scaler.fit(train_df[outlier_columns])\n",
        "\n",
        "# Now transform our data using this scaler, replacing the original data\n",
        "train_df[outlier_columns] = scaler.transform(train_df[outlier_columns])\n",
        "train_df_bak[outlier_columns].hist()\n",
        "plt.show()\n",
        "train_df[outlier_columns].hist()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0NViyECoTYOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "train_df_bak.sort_values(by='class', ignore_index=True, inplace=True)\n",
        "train_df.sort_values(by='class', ignore_index=True, inplace=True)\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "it3i7zvqJg3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=['class'], inplace=True)\n",
        "test_df.shape"
      ],
      "metadata": {
        "id": "7qI7erL0j95a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = train_df.iloc[:, 0:-1].copy()\n",
        "print(data_df)\n",
        "label_df = train_df['class'].copy()\n",
        "print(label_df)\n",
        "print(data_df.shape)\n",
        "print(label_df.shape)"
      ],
      "metadata": {
        "id": "RjB5Rx50EJni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can plot a histogram of all the data together\n",
        "data_df.hist(figsize=(12,12))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ipzJyqv7lse9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify and remove irrelevant attributes."
      ],
      "metadata": {
        "id": "2u9fx8GEZ8fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove index column\n",
        "print(f\"Before dropping {data_df.shape}\")\n",
        "drop_columns = ['index']\n",
        "print(drop_columns)\n",
        "data_df.drop(columns=drop_columns, inplace=True)\n",
        "print(f\"After dropping {data_df.shape}\")"
      ],
      "metadata": {
        "id": "igAFdV68xgQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=drop_columns, inplace=True)\n",
        "test_df.shape"
      ],
      "metadata": {
        "id": "cUMu03c0kkkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "cor = train_df.corr(numeric_only=True).abs()\n",
        "fig, ax = plt.subplots(1,1,figsize=(24,20))\n",
        "# use seaborn to do the plot\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds, ax=ax)\n",
        "cols = cor.columns\n",
        "config_cor_hi_threshold = 0.8\n",
        "config_cor_lw_threshold = 0.1\n",
        "cor_hi_columns = []\n",
        "cor_low_columns = []\n",
        "for i,col in enumerate(cols):\n",
        "  for j in range(i + 1, len(cols)-1): # Ignore the last column: class\n",
        "    if cor.iloc[i,j] > config_cor_hi_threshold:\n",
        "      print(cols[i], ' vs. ', cols[j], cor.iloc[i,j])\n",
        "      if cols[j] not in cor_hi_columns:\n",
        "          cor_hi_columns.append(cols[j])\n",
        "for i,col in enumerate(cols):\n",
        "  if cor.iloc[i,len(cols)-1] < config_cor_lw_threshold:\n",
        "    print(cols[i], \" vs. \", cols[len(cols)-1], cor.iloc[i,len(cols)-1])\n",
        "    if cols[i] != 'index':\n",
        "      cor_low_columns.append(cols[i])\n",
        "\n",
        "print(cor_hi_columns)\n",
        "print(cor_low_columns)"
      ],
      "metadata": {
        "id": "z77RaB5ZoVar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before dropping {data_df.shape}\")\n",
        "print(cor_hi_columns)\n",
        "data_df.drop(columns=cor_hi_columns,\n",
        "           inplace=True, errors='ignore')\n",
        "print(cor_low_columns)\n",
        "data_df.drop(columns=cor_low_columns,\n",
        "           inplace=True, errors='ignore')\n",
        "print(f\"After dropping {data_df.shape}\")"
      ],
      "metadata": {
        "id": "7NABdq3cz3ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=cor_hi_columns, inplace=True, errors='ignore')\n",
        "test_df.drop(columns=cor_low_columns, inplace=True, errors='ignore')\n",
        "test_df.shape"
      ],
      "metadata": {
        "id": "ourVFopLksRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove dtype=object columns\n",
        "non_number_columns = data_df.select_dtypes(exclude=['number']).columns\n",
        "print(non_number_columns)"
      ],
      "metadata": {
        "id": "bd0rgZI-ahSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out which columns you want to drop from above, and put their names in the list below\n",
        "print(f\"Before dropping {data_df.shape}\")\n",
        "print(non_number_columns)\n",
        "data_df.drop(columns=non_number_columns,\n",
        "           inplace=True)\n",
        "print(f\"After dropping {data_df.shape}\")"
      ],
      "metadata": {
        "id": "pHyGQbivqzmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=non_number_columns, inplace=True)\n",
        "test_df.shape"
      ],
      "metadata": {
        "id": "CUzTY904kyLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cite: https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "print(f\"Before dropping {data_df.shape}\")\n",
        "# TODO: How much to set ? Need handle test_df at the same time\n",
        "config_p = 0.8\n",
        "sel = VarianceThreshold(threshold=(config_p * (1 - config_p)))\n",
        "# sel.fit_transform(data_df)\n",
        "print(f\"After dropping {data_df.shape}\")"
      ],
      "metadata": {
        "id": "GIh7X-n6-R4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect and handle missing entries."
      ],
      "metadata": {
        "id": "GS7M9JrMjw5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find which columns have missing data\n",
        "def missing(df):\n",
        "  \"\"\"\n",
        "  For each attribute/column in the dataframe `df`, count the number of missing entries.\n",
        "  Return a list of all the coulmns with more than 80% missing entries.\n",
        "  \"\"\"\n",
        "  missing_dict = dict()\n",
        "  total = df.shape[0] # shape[0] is the number of rows\n",
        "  for attribute in df.columns:\n",
        "    missing = df[attribute].isna().sum() # count the number of Null/nan/na values\n",
        "    frac = missing/total * 100 # as a percentage\n",
        "    missing_dict[attribute] = frac\n",
        "  return missing_dict"
      ],
      "metadata": {
        "id": "oQbBqYeej4uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict = missing(data_df)\n",
        "m_dict"
      ],
      "metadata": {
        "id": "9CkC3SCtj6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict_test = missing(test_df)\n",
        "m_dict_test"
      ],
      "metadata": {
        "id": "m6Xx7M61lG1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at each attribute/frac pair in the dict and choose those with a frac that is >80\n",
        "conf_drop_frac = 20\n",
        "cols_to_drop = [ att for att,frac in m_dict.items() if frac > conf_drop_frac]\n",
        "cols_to_drop"
      ],
      "metadata": {
        "id": "pVEMhaxEjk8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out which columns you want to drop from above, and put their names in the list below\n",
        "print(f\"Before dropping {data_df.shape}\")\n",
        "print(cols_to_drop)\n",
        "data_df.drop(columns=cols_to_drop,\n",
        "           inplace=True)\n",
        "print(f\"After dropping {data_df.shape}\")"
      ],
      "metadata": {
        "id": "FA3EDXeORnl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm that our data frame now has fewer columns (was 280)\n",
        "data_df.columns"
      ],
      "metadata": {
        "id": "XtkS5EufRsT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=cols_to_drop, inplace=True)\n",
        "test_df.shape"
      ],
      "metadata": {
        "id": "DuyI0AD3l3_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dict = missing(data_df)\n",
        "m_dict"
      ],
      "metadata": {
        "id": "akDRZ7gZURRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at each attribute/frac pair in the dict and choose those with a frac that is <5\n",
        "conf_impute_frac = 5\n",
        "cols_to_impute = [ att for att,frac in m_dict.items() if 0 < frac < conf_impute_frac]\n",
        "cols_to_impute"
      ],
      "metadata": {
        "id": "uyQGUbt6e15K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_to_impute:\n",
        "  print(col, \"missing data\", m_dict[col])"
      ],
      "metadata": {
        "id": "Fy3hJJ-Se7iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_to_impute:\n",
        "  # compute the mean\n",
        "  mean = data_df[col].mean()\n",
        "  # now use the fillna function to replace the NaN avalues with the mean value\n",
        "  data_df.fillna({col: mean}, inplace=True)"
      ],
      "metadata": {
        "id": "ZVTTjWJ9e5ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# double check the missing data\n",
        "m_dict = missing(data_df)\n",
        "for col in cols_to_impute:\n",
        "  print(col, \"missing data\", m_dict[col])"
      ],
      "metadata": {
        "id": "COEjPPdFjHGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "data_df.shape\n",
        "label_df.shape\n",
        "X_new = SelectKBest(f_classif, k=7).fit_transform(data_df, label_df) # Need no nan\n",
        "X_new.shape"
      ],
      "metadata": {
        "id": "H57y786CiOak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.describe()"
      ],
      "metadata": {
        "id": "ijWS5XSqAJ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "metadata": {
        "id": "Y0vkcZ-YjoyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect and handle duplicates (both instances and attributes)."
      ],
      "metadata": {
        "id": "yw4yZT4gaFaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows have the same data\n",
        "dup_rows = data_df.duplicated()\n",
        "# recall that true = 1, false = 0\n",
        "print(dup_rows.sum())\n",
        "dup_row_indexes = dup_rows.index[dup_rows == True].tolist()\n",
        "print(dup_row_indexes)\n",
        "print(data_df.shape)\n",
        "data_df.drop(index=dup_row_indexes, inplace=True)\n",
        "print(data_df.shape)\n",
        "print(label_df.shape)\n",
        "label_df.drop(index=dup_row_indexes, inplace=True)\n",
        "print(label_df.shape)"
      ],
      "metadata": {
        "id": "XNIOtVfubvEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicated columns\n",
        "dup_cols = data_df.T.duplicated()\n",
        "dup_cols2 = data_df.columns.duplicated()\n",
        "# recall that true = 1, false = 0\n",
        "print(dup_cols.sum())\n",
        "print(dup_cols2.sum())"
      ],
      "metadata": {
        "id": "mHrUrZNibws9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select suitable data types for attributes."
      ],
      "metadata": {
        "id": "D4Lc0BSgaG_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names\")\n",
        "print(data_df.columns)\n",
        "print()\n",
        "print(\"Data types\")\n",
        "print(data_df.dtypes)\n",
        "print(data_df.shape)\n",
        "print(train_df.shape)"
      ],
      "metadata": {
        "id": "nwbxdVF3Uz4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.describe()"
      ],
      "metadata": {
        "id": "MfdJ77PtU21H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can plot a histogram of all the data together\n",
        "data_df.hist(figsize=(12,12))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ui5arY6NU80e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_columns = data_df.select_dtypes(include=['int64']).columns\n",
        "print(int_columns)"
      ],
      "metadata": {
        "id": "XsFtlT51Fsz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for int_col in int_columns:\n",
        "  print(data_df[int_col].describe())\n",
        "  data_df[int_col].hist(figsize=(12,12))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6vyvIaMoF1C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_df = data_df.join(label_df)\n",
        "cor = new_train_df.corr().abs()\n",
        "fig, ax = plt.subplots(1,1,figsize=(24,20))\n",
        "# use seaborn to do the plot\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds, ax=ax)"
      ],
      "metadata": {
        "id": "rKYyPJ-e3zU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform data transformation (such as scaling/standardization) if needed."
      ],
      "metadata": {
        "id": "np_dcGq5aIcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "PzKb5pM5VNGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose all the numeric type attributes (all of them)\n",
        "numeric_attributes = data_df.select_dtypes(include='number').columns\n",
        "numeric_attributes"
      ],
      "metadata": {
        "id": "hZneI5S5SLNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a standard scaler\n",
        "scaler = StandardScaler()\n",
        "# Determine the mean/std for each column and set up the scaler\n",
        "scaler.fit(data_df[numeric_attributes])\n",
        "\n",
        "# Now transform our data using this scaler, replacing the original data\n",
        "data_df[numeric_attributes] =  scaler.transform(data_df[numeric_attributes])\n",
        "# if you have other data frames that you want to scale with the same transform you can do it as\n",
        "# other_df[numeric_attributes] = scaler.transform(other_df[numeric_attributes])\n"
      ],
      "metadata": {
        "id": "dNO9urjpSOmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[numeric_attributes] =  scaler.transform(test_df[numeric_attributes])"
      ],
      "metadata": {
        "id": "0i49gdhImSqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify that this worked\n",
        "# the mean should be close to zero, and the std should be close to 1.\n",
        "data_df.describe()"
      ],
      "metadata": {
        "id": "cbRfep5XSQe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "metadata": {
        "id": "8SELsK-imoz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape, data_df.shape"
      ],
      "metadata": {
        "id": "NMXfv-Twmuph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform other data preparation operations (This is optional, bonus marks will be awarded for novel ideas)."
      ],
      "metadata": {
        "id": "bbI4AFCgaKky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Data classification"
      ],
      "metadata": {
        "id": "VC001-VSCRAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class imbalance\n",
        "\n",
        "The original labelled data is not equally distributed between the three classes. You need to demonstrate that such an issue exists within the data, explain the importance of this issue, and describe how you address this problem."
      ],
      "metadata": {
        "id": "dyvhGM6sCXel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_df.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZprzKqJAK1i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normally our we are given train/test data separately\n",
        "# hewever for this prac we will take 25% of the iris data can pretend that it's test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "config_train_ratio = 0.70\n",
        "config_validation_ratio = 0.15\n",
        "config_test_ratio = 0.15\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_df, label_df,\n",
        "                                                    test_size=1 - config_train_ratio,\n",
        "                                                    random_state=4)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
        "                                                test_size=config_test_ratio/(config_test_ratio + config_validation_ratio),\n",
        "                                                random_state=4)\n",
        "\n",
        "print(X_train, X_val, X_test)\n",
        "print(y_train, y_val, y_test)"
      ],
      "metadata": {
        "id": "3Xo5QQbsYO5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ],
      "metadata": {
        "id": "2TfBsSBEYRDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G9kvL55fgc73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=4)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "print(X_resampled.shape, y_resampled.shape)\n",
        "\n",
        "# X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "# print(X_resampled.shape, y_resampled.shape)\n",
        "# clf_smote = LogisticRegression().fit(X_resampled, y_resampled)\n",
        "\n",
        "# X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
        "# print(X_resampled.shape, y_resampled.shape)\n",
        "# clf_adasyn = LogisticRegression().fit(X_resampled, y_resampled)\n",
        "\n",
        "df_oversampled = pd.DataFrame(X_resampled, columns=X_train.columns)\n",
        "df_oversampled['class'] = y_resampled\n",
        "# For compare\n",
        "# df_oversampled = pd.DataFrame(X_train, columns=X_train.columns)\n",
        "# df_oversampled['class'] = y_train\n",
        "df_oversampled.head()\n",
        "print(df_oversampled.shape)\n",
        "\n",
        "# oversampler = RandomOverSampler(random_state=4)\n",
        "# X_resampled_val, y_resampled_val = oversampler.fit_resample(X_val, y_val)\n",
        "# print(X_resampled_val.shape, y_resampled_val.shape)\n",
        "# df_oversampled_val = pd.DataFrame(X_resampled_val, columns=X_val.columns)\n",
        "# df_oversampled_val['class'] = y_resampled_val\n",
        "# df_oversampled_val.head()\n",
        "\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# undersampler = RandomUnderSampler(random_state=4)\n",
        "# X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "# print(X_resampled.shape, y_resampled.shape)\n",
        "# df_undersampled = pd.DataFrame(X_resampled, columns=X_train.columns)\n",
        "# df_undersampled['class'] = y_resampled\n",
        "# df_undersampled.head()"
      ],
      "metadata": {
        "id": "cQpP7xq5Os7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_oversampled['class'].hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Td_wXEjgI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_oversampled.head())\n",
        "df_oversampled.sort_values(by='class', ignore_index=True, inplace=True)\n",
        "print(df_oversampled.head())"
      ],
      "metadata": {
        "id": "stBKZQ5pRQ6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_oversampled.iloc[:, 0:-1].copy()\n",
        "y_train = df_oversampled['class'].copy()\n",
        "# X_val = df_oversampled_val.iloc[:, 0:-1].copy()\n",
        "# y_val = df_oversampled_val['class'].copy()"
      ],
      "metadata": {
        "id": "V_8an47yReQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ],
      "metadata": {
        "id": "0Qgi_2foRtFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_oversampled.head()"
      ],
      "metadata": {
        "id": "le1ytI7ACEtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, KFold, ShuffleSplit"
      ],
      "metadata": {
        "id": "KEYKeonJI5Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is random sampling\n",
        "ss = ShuffleSplit(n_splits=10, test_size=15, random_state=4)\n",
        "# This is non-random sampling, we just break the data in to 10 contiguous sub-sets\n",
        "kf = KFold(n_splits=10)\n",
        "# Ensuring the balance between classes in the model/validate sets\n",
        "# means we should use stratified sampling\n",
        "skf = StratifiedKFold(n_splits=10)"
      ],
      "metadata": {
        "id": "S9_uduldYjDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell sets up a nice visulisation that I found on the scikit-learn documentation page.\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "cmap_data = plt.cm.Paired\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "\n",
        "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
        "    \"\"\"\n",
        "    Create a sample plot for indices of a cross-validation object.\n",
        "    Adapted from https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#define-a-function-to-visualize-cross-validation-behavior\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cv: cross validation method\n",
        "\n",
        "    X : training data\n",
        "\n",
        "    y : data labels\n",
        "\n",
        "    group : group labels\n",
        "\n",
        "    ax : matplolib axes object\n",
        "\n",
        "    n_splits : number of splits\n",
        "\n",
        "    lw : line width for plotting\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the training/testing visualizations for each CV split\n",
        "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
        "        # Fill in indices with the training/test groups\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1\n",
        "        indices[tr] = 0\n",
        "\n",
        "        # Visualize the results\n",
        "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "\n",
        "    # Plot the data classes and groups at the end\n",
        "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
        "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
        "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    # Formatting\n",
        "    yticklabels = list(range(n_splits)) + ['class', 'group']\n",
        "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+2.2, -.2])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    return ax"
      ],
      "metadata": {
        "id": "1iGephFQYogg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a figure with three subplots\n",
        "fig, ax = plt.subplots(1,3, figsize=(18,6))\n",
        "# visualise the ShulffleSplit algorithm\n",
        "plot_cv_indices(ss,\n",
        "                X_train, y_train,\n",
        "                group=None,\n",
        "                ax=ax[0],\n",
        "                n_splits=10)\n",
        "# visualise the KFolds algorithm\n",
        "plot_cv_indices(kf,\n",
        "                X_train, y_train,\n",
        "                group=None,\n",
        "                ax=ax[1],\n",
        "                n_splits=10)\n",
        "# visualise the StratifiedKFolds algorithm\n",
        "plot_cv_indices(skf,\n",
        "                X_train, y_train,\n",
        "                group=None,\n",
        "                ax=ax[2],\n",
        "                n_splits=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2oHgQkgYrhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training and tuning\n",
        "\n",
        "Every classifier typically has hyperparameters to tune in order. For each classifier, you need to select (at least one) and explain the tuning hyperparameters of your choice. You must select and describe a suitable cross-validation/validation scheme that can measure the performance of your model on labelled data well and can address the class imbalance issue. Then you will need to conduct the actual tuning of your model and report the tuning results in detail. You are expected to look at several classification performance metrics and make comments on the classification performance of each model. Finally, you will need to clearly indicate and justify the selected values of the tuning hyperparameters of each model."
      ],
      "metadata": {
        "id": "7Kqd_VBdCoPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, PredefinedSplit, GridSearchCV\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "q00thp1UYwhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(len(split_index))\n",
        "\n",
        "X = pd.concat([X_train, X_val])\n",
        "y = pd.concat([y_train, y_val])\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "cYCNdRTeIYVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_name = \"Name\"\n",
        "comp_param = \"Param\"\n",
        "comp_score = \"Score\"\n",
        "comp_val = \"Validation\"\n",
        "comp_test = \"Test\"\n",
        "model_comp_dict = {comp_name:[], comp_param:[], comp_score:[], comp_val:[], comp_test:[]}"
      ],
      "metadata": {
        "id": "8nOC74DojMpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, make_scorer\n",
        "precision_scorer = make_scorer(precision_score, average='weighted')"
      ],
      "metadata": {
        "id": "MG5goxSExFBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model: KNN"
      ],
      "metadata": {
        "id": "bUZkKwQgZPH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of all the parameters we'll be iterating over\n",
        "parameters = {'weights': ['uniform','distance'], # this should be the different weighting schemes\n",
        "              'n_neighbors':[1,3,7,11,17,21,25,30,35,40,45,50,55,60]} # this should be a list of the nearest neigbhours\n",
        "# make a classifier object\n",
        "knn = KNeighborsClassifier()\n",
        "# create a GridSearchCV object to do the training with cross validation\n",
        "gscv = GridSearchCV(estimator=knn,\n",
        "                    param_grid=parameters,\n",
        "                    # cv=skf,  # the cross validation folding pattern\n",
        "                    cv=pds,\n",
        "                    # scoring='accuracy')\n",
        "                    scoring=precision_scorer)\n",
        "# now train our model\n",
        "best_knn = gscv.fit(X, y)"
      ],
      "metadata": {
        "id": "Vwgvj4JBYzBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_knn.best_params_, best_knn.best_score_ # ({'n_neighbors': 50, 'weights': 'distance'}, 0.9213341032832865)\n",
        "# ({'n_neighbors': 35, 'weights': 'distance'}, 0.8519515477792732)\n",
        "\n",
        "# Final: ({'n_neighbors': 25, 'weights': 'distance'}, 0.8703840669201928)\n",
        "# ({'n_neighbors': 35, 'weights': 'distance'}, 0.9134834913944504)"
      ],
      "metadata": {
        "id": "PpU46UZuY10N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(weights = best_knn.best_params_['weights'],\n",
        "                            n_neighbors = best_knn.best_params_['n_neighbors'])\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9QBAgLRJY4wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.score(X_val, y_val)\n",
        "# 0.8519515477792732\n",
        "# final: 0.847913862718708\n",
        "# 0.8600269179004038"
      ],
      "metadata": {
        "id": "Vl-CWO7GDDgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.score(X_test, y_test) # 0.8529886914378029\n",
        "# 0.845222072678331\n",
        "# final: 0.847913862718708\n",
        "# 0.8492597577388964"
      ],
      "metadata": {
        "id": "psXibGP_TztN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_dict[comp_name].append(\"KNN\")\n",
        "model_comp_dict[comp_param].append(best_knn.best_params_)\n",
        "model_comp_dict[comp_score].append(best_knn.best_score_)\n",
        "model_comp_dict[comp_val].append(knn.score(X_val, y_val))\n",
        "model_comp_dict[comp_test].append(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "dM_9pmuwlKZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(knn,\n",
        "                                      X_test, y_test,\n",
        "                                      ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cccCfI6UY6lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model: DT"
      ],
      "metadata": {
        "id": "FCV-WNxRZU4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "jqSR4dgJZW1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of all the parameters we'll be iterating over\n",
        "parameters = {'criterion': ('gini','entropy'),  # this should be the different splitting criteria\n",
        "              'min_samples_split': [2,3,4,5,7,10,15,20], # this should be the different values for min_samples_split\n",
        "              'max_depth': [5,7,8,9,10,11,12,13,14,15]}\n",
        "dtc = tree.DecisionTreeClassifier()\n",
        "gscv = GridSearchCV(estimator=dtc,\n",
        "                    param_grid=parameters,\n",
        "                    cv=pds, #5\n",
        "                    # scoring='accuracy')\n",
        "                    scoring=precision_scorer)\n",
        "best_dtc = gscv.fit(X, y)"
      ],
      "metadata": {
        "id": "6fuge8E9ZaVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_dtc.best_params_, best_dtc.best_score_ # ({'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 2}, 0.8464952978056427)\n",
        "#({'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 4}, 0.7577388963660835)"
      ],
      "metadata": {
        "id": "ET_2Y-OfUh6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = tree.DecisionTreeClassifier(criterion=best_dtc.best_params_['criterion'],\n",
        "                                  min_samples_split=best_dtc.best_params_['min_samples_split'],\n",
        "                                  max_depth=best_dtc.best_params_['max_depth'])\n",
        "dtc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ef3hXgr4Zbtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc.score(X_val, y_val)\n",
        "# 0.7496635262449529"
      ],
      "metadata": {
        "id": "YitU4RgXNpax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc.score(X_test, y_test) # 0.7568659127625202\n",
        "# 0.7510094212651414"
      ],
      "metadata": {
        "id": "xzUd4hBpUjv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
        "tree.plot_tree(dtc,\n",
        "               filled=True, # color the nodes based on class/purity\n",
        "               ax=ax, fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AeHLh8lNZdI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_dict[comp_name].append(\"DT\")\n",
        "model_comp_dict[comp_param].append(best_dtc.best_params_)\n",
        "model_comp_dict[comp_score].append(best_dtc.best_score_)\n",
        "model_comp_dict[comp_val].append(dtc.score(X_val, y_val))\n",
        "model_comp_dict[comp_test].append(dtc.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "0-OI4kGtlyoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(dtc,\n",
        "                                      X_test, y_test,\n",
        "                                      # display_labels=iris['target_names'],\n",
        "                                      ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4gA6B7BLZfTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model: NB"
      ],
      "metadata": {
        "id": "Ra9KBK_cZhtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import naive_bayes\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mescOVQUZi8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of all the parameters we'll be iterating over\n",
        "parameters = {'var_smoothing': [1e-10, 1e-09, 1e-08, 1e-07]}\n",
        "nb = naive_bayes.GaussianNB()\n",
        "gscv = GridSearchCV(estimator=nb,\n",
        "                    param_grid=parameters,\n",
        "                    cv=pds, #5\n",
        "                    # scoring='accuracy')\n",
        "                    scoring=precision_scorer)\n",
        "best_nb = gscv.fit(X, y)"
      ],
      "metadata": {
        "id": "BoHq9MqKZkR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_nb.best_params_, best_nb.best_score_ #({'var_smoothing': 1e-10}, 0.6944818304172274)"
      ],
      "metadata": {
        "id": "CdrRz8t1cWhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = naive_bayes.GaussianNB(var_smoothing=best_nb.best_params_['var_smoothing'])\n",
        "nb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vCozIv0tcbOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb.score(X_val, y_val)"
      ],
      "metadata": {
        "id": "MXCx0e3Ucbv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "9WoeVC5Bcd_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no parameters to adjust so no need to optimise, just train\n",
        "# nb = naive_bayes.GaussianNB()\n",
        "# nb.fit(X_train, y_train)\n",
        "# y_pred = nb.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"NB accuracy is {accuracy:5.3f}\")\n",
        "# print(nb.score(X_test, y_test))\n",
        "# NB accuracy is 0.698  0.6978998384491115"
      ],
      "metadata": {
        "id": "3oj6t-I_cOsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_dict[comp_name].append(\"NB\")\n",
        "model_comp_dict[comp_param].append(best_nb.best_params_)\n",
        "model_comp_dict[comp_score].append(best_nb.best_score_)\n",
        "model_comp_dict[comp_val].append(nb.score(X_val, y_val))\n",
        "model_comp_dict[comp_test].append(nb.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "2Mj_9PgSmLs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "ConfusionMatrixDisplay.from_estimator(nb,\n",
        "                                      X_test, y_test,\n",
        "                                      # display_labels=iris['target_names'],\n",
        "                                      ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sxYREOenXixM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model: SVM"
      ],
      "metadata": {
        "id": "qodcc_8tawhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "_GfPqgL0Y5od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of all the parameters we'll be iterating over\n",
        "parameters = {'kernel': ('linear', 'poly', 'rbf'),  # this should be the different splitting criteria\n",
        "              'C': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0], # this should be the different values for min_samples_split\n",
        "              'gamma': ['scale', 'auto']}\n",
        "svc = svm.SVC()\n",
        "gscv = GridSearchCV(estimator=svc,\n",
        "                    param_grid=parameters,\n",
        "                    cv=pds, #5\n",
        "                    # scoring='accuracy')\n",
        "                    scoring=precision_scorer)\n",
        "best_svc = gscv.fit(X, y)"
      ],
      "metadata": {
        "id": "jiOxaXC5X0Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_svc.best_params_, best_svc.best_score_ # ({'C': 3.0, 'gamma': 'scale', 'kernel': 'rbf'}, 0.9500409173403728)\n",
        "# ({'C': 4.0, 'gamma': 'scale', 'kernel': 'rbf'}, 0.8721399730820996)"
      ],
      "metadata": {
        "id": "V77PVKQXX1SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = svm.SVC(kernel=best_svc.best_params_['kernel'],\n",
        "                                  C=best_svc.best_params_['C'],\n",
        "                                  gamma=best_svc.best_params_['gamma'])\n",
        "svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BeJ-9XGWX3Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc.score(X_val, y_val) # 0.8721399730820996"
      ],
      "metadata": {
        "id": "ky2ei2VHO5wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc.score(X_test, y_test) # 0.9063004846526656\n",
        "# 0.873485868102288"
      ],
      "metadata": {
        "id": "x9x3atyuX42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_dict[comp_name].append(\"SVM\")\n",
        "model_comp_dict[comp_param].append(best_svc.best_params_)\n",
        "model_comp_dict[comp_score].append(best_svc.best_score_)\n",
        "model_comp_dict[comp_val].append(svc.score(X_val, y_val))\n",
        "model_comp_dict[comp_test].append(svc.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "0J0FXLNqmUZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_dict"
      ],
      "metadata": {
        "id": "uiwDN8GImdK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(svc,\n",
        "                                      X_test, y_test,\n",
        "                                      # display_labels=iris['target_names'],\n",
        "                                      ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kq2JZ1-YX79I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model comparison\n",
        "\n",
        "Once you have finished tuning all models, you will need to compare them and explain how you select the best two models for producing the prediction on the 500 test samples."
      ],
      "metadata": {
        "id": "bhkvOik4CsXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "s1E4w5V6CvMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp_pd = pd.DataFrame(model_comp_dict)\n",
        "model_comp_pd"
      ],
      "metadata": {
        "id": "rS1cz93cmvgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict using 2 models"
      ],
      "metadata": {
        "id": "c-PgX20nh_vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.describe()"
      ],
      "metadata": {
        "id": "TaIwKj694EOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "metadata": {
        "id": "Lu0O0m9d4CQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape, data_df.shape"
      ],
      "metadata": {
        "id": "eQKLuRgnh-mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_svc = svc.predict(test_df)\n",
        "y_predict_knn = knn.predict(test_df)"
      ],
      "metadata": {
        "id": "X-6V0k7zm5qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_svc"
      ],
      "metadata": {
        "id": "W-MsNBQTnWVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_knn"
      ],
      "metadata": {
        "id": "nodVZVeEnXaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_predict_svc == y_predict_knn).sum()"
      ],
      "metadata": {
        "id": "kp9rQN6yvlNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(out_df)"
      ],
      "metadata": {
        "id": "sgIkksipwpoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df['Predict1'] = y_predict_svc\n",
        "out_df['Predict2'] = y_predict_knn"
      ],
      "metadata": {
        "id": "O3ioJq7OoCs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df"
      ],
      "metadata": {
        "id": "fUnJzSCWpLHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving data to an sqlite database"
      ],
      "metadata": {
        "id": "L1DOHOL4amxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "FvXbfwTBalgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con = sqlite3.connect('Answers.sqlite')"
      ],
      "metadata": {
        "id": "FJwXyy88arJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df.to_sql(name='predict',\n",
        "          con=con,\n",
        "          if_exists='replace',\n",
        "          index=False) # don't save the index column to the output"
      ],
      "metadata": {
        "id": "E9h3Cehkartr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con.close()"
      ],
      "metadata": {
        "id": "f09_uu-Vas0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}